{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from yoloDetector import YoloDetector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: numba in c:\\users\\admin\\.conda\\envs\\main_py312\\lib\\site-packages (0.60.0)\n",
      "Requirement already satisfied: llvmlite<0.44,>=0.43.0dev0 in c:\\users\\admin\\.conda\\envs\\main_py312\\lib\\site-packages (from numba) (0.43.0)\n",
      "Requirement already satisfied: numpy<2.1,>=1.22 in c:\\users\\admin\\.conda\\envs\\main_py312\\lib\\site-packages (from numba) (1.26.4)\n"
     ]
    }
   ],
   "source": [
    "!pip install numba"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Khoi tao: model, label_path va image_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "detector = YoloDetector() #initialize the detector\n",
    "label_path = r\"C:/data_object_image_2/training/label_2\"\n",
    "image_path = r\"C:/data_object_image_2/training/image_2\"\n",
    "import os\n",
    "import numpy as np\n",
    "import cv2\n",
    "import tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bat dau chay tu doan code nay"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def IoU(box1, box2):\n",
    "   \n",
    "    x1, y1, w1, h1 = box1\n",
    "    x2, y2, w2, h2 = box2\n",
    "    \n",
    "    iou = 0.0\n",
    "\n",
    "    \n",
    "    xA = max(x1, x2)\n",
    "    yA = max(y1, y2)\n",
    "    xB = min(x1 + w1, x2 + w2)\n",
    "    yB = min(y1 + h1, y2 + h2)\n",
    "\n",
    "    interArea = max(0, xB - xA) * max(0, yB - yA)\n",
    "\n",
    "    box1Area = w1 * h1\n",
    "    box2Area = w2 * h2\n",
    "\n",
    "    iou = interArea / float(box1Area + box2Area - interArea)\n",
    "\n",
    "    return iou"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tqdm\n",
    "\n",
    "def evaluate_detector(min_pixel, max_occlusion, max_truncation, detector, path = 'data/test_ann.txt', images_path = '',):\n",
    "    TP = [0, 0, 0, 0, 0]\n",
    "    FP = [0, 0, 0, 0, 0]\n",
    "    FN = [0, 0, 0, 0, 0]\n",
    "\n",
    "    ### tạo đối tượng CascadeClassifier và khởi tạo bằng file xml đã học được \n",
    "    # our_cascade = cv2.CascadeClassifier('cascade.xml')\n",
    "\n",
    "    threshold = 0.3\n",
    "    cnt = 0\n",
    "    \n",
    "    for one_path in tqdm.tqdm(os.listdir(path), desc=\"Processing\", unit=\"file\"):\n",
    "    # for one_path in ['000003.txt']:\n",
    "        # print(one_path)\n",
    "        img = cv2.imread(os.path.join(images_path, one_path[:-3] + 'png'))\n",
    "        # print(img)\n",
    "        detector.DetectFrame(img)\n",
    "        cars = []\n",
    "        pedestrian = []\n",
    "        truck = []\n",
    "        bicycle = []\n",
    "        other = []\n",
    "        for i in detector._object_info:\n",
    "            if i.label == 'car':\n",
    "                cars.append(i)\n",
    "            elif i.label == 'person':\n",
    "                pedestrian.append(i)\n",
    "            elif i.label == 'truck':\n",
    "                truck.append(i)\n",
    "            elif i.label == 'bicycle':\n",
    "                bicycle.append(i)\n",
    "            else:\n",
    "                other.append(i)\n",
    "        true_detect = [0,0,0,0,0]\n",
    "        with open(os.path.join(path, one_path), 'r') as f:\n",
    "        \n",
    "            for line in f:\n",
    "                #preprocess path\n",
    "                line = line.strip().split(' ') #\n",
    "                \n",
    "                truth_box = [float(line[i]) for i in range(4, 8)]   # x1, y1, x2, y2\n",
    "                truth_box[2] = truth_box[2] - truth_box[0]\n",
    "                truth_box[3] = truth_box[3] - truth_box[1]\n",
    "                # if(truth_box[3] < min_pixel): print('skip: pixel'); continue\n",
    "                # if(float(line[1]) > max_truncation): print('skip: max_truncation');continue\n",
    "                # if(float(line[2]) > max_occlusion): print('skip: max_occulusion'); continue\n",
    "                type = line[0]\n",
    "                if type == 'Car':\n",
    "                    if len(cars) == 0:\n",
    "                        FN[0] += 1\n",
    "                        continue\n",
    "                    for detection in cars:\n",
    "                        box = (detection.x, detection.y, detection.width, detection.height)\n",
    "                        \n",
    "                        t = IoU(box, truth_box)\n",
    "                        if t >= threshold:\n",
    "                            true_detect[0] += 1\n",
    "                            break\n",
    "                    else:\n",
    "                        FN[0] += 1\n",
    "                elif type == 'Pedestrian':\n",
    "                    if len(pedestrian) == 0:\n",
    "                        FN[1] += 1\n",
    "                        continue\n",
    "                    for detection in pedestrian:\n",
    "                        box = (detection.x, detection.y, detection.width, detection.height)\n",
    "                        t = IoU(box, truth_box)\n",
    "                        if t >= threshold:\n",
    "                            true_detect[1] += 1\n",
    "                            break\n",
    "                    else:\n",
    "                        FN[1] += 1\n",
    "                elif type == 'Truck':\n",
    "                    if len(truck) == 0:\n",
    "                        FN[2] += 1\n",
    "                        continue\n",
    "                    for detection in truck:\n",
    "                        box = (detection.x, detection.y, detection.width, detection.height)\n",
    "                        t = IoU(box, truth_box)\n",
    "                        if t >= threshold:\n",
    "                            true_detect[2] += 1\n",
    "                            break\n",
    "                    else:\n",
    "                        FN[2] += 1\n",
    "                elif type == 'Cyclist':\n",
    "                    if len(bicycle) == 0:\n",
    "                        FN[3] += 1\n",
    "                        continue\n",
    "                    for detection in bicycle:\n",
    "                        box = (detection.x, detection.y, detection.width, detection.height)\n",
    "                        t = IoU(box, truth_box)\n",
    "                        if t >= threshold:\n",
    "                            true_detect[3] += 1\n",
    "                            break\n",
    "                    else:\n",
    "                        FN[3] += 1\n",
    "                else:\n",
    "                    if len(other) == 0:\n",
    "                        FN[4] += 1\n",
    "                        continue\n",
    "                    for detection in other:\n",
    "                        box = (detection.x, detection.y, detection.width, detection.height)\n",
    "                        t = IoU(box, truth_box)\n",
    "                        if t >= threshold:\n",
    "                            true_detect[4] += 1\n",
    "                            break\n",
    "                    else:\n",
    "                        FN[4] += 1\n",
    "\n",
    "        for i in range(5):\n",
    "            TP[i] += true_detect[i]\n",
    "            if i == 0: FP[i] += len(cars) - true_detect[i]\n",
    "            elif i == 1: FP[i] += len(pedestrian) - true_detect[i]\n",
    "            elif i == 2: FP[i] += len(truck) - true_detect[i]\n",
    "            elif i == 3: FP[i] += len(bicycle) - true_detect[i]\n",
    "            elif i == 4: FP[i] += len(other) - true_detect[i]\n",
    "\n",
    "        cnt += 1\n",
    "        \n",
    "    TP = np.array(TP)\n",
    "    FP = np.array(FP)\n",
    "    FN = np.array(FN)\n",
    "    precision = 1.0 * TP / (TP + FP)\n",
    "    recall = 1.0 * TP / (TP + FN)\n",
    "    f1 = 2 * precision * recall / (precision + recall)\n",
    "    \n",
    "    return precision, recall, f1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Easy task: height of pixel >= 40, truncated <= 0.15, ko bi che phu (0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6.683598449405159 %\n"
     ]
    }
   ],
   "source": [
    "#easy task\n",
    "precision, recall, f1 = evaluate_detector(40,0,0.15, detector, label_path, images_path = image_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "object_types = [\"Car\", \"Pedestrian\", \"Truck\", \"Cyclist\", \"Other\"]\n",
    "\n",
    "# Tạo DataFrame từ các giá trị\n",
    "df = pd.DataFrame({\n",
    "    \"Object Type\": object_types,\n",
    "    \"Precision\": precision,\n",
    "    \"Recall\": recall,\n",
    "    \"F1\": f1\n",
    "})\n",
    "\n",
    "# Hiển thị DataFrame dưới dạng bảng\n",
    "print(df.to_string(index=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Medium task: height of pixel < 25,>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing:   0%|          | 20/7481 [00:19<1:59:27,  1.04file/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[11], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m#Medium task\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m precision, recall, f1 \u001b[38;5;241m=\u001b[39m \u001b[43mevaluate_detector\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m25\u001b[39;49m\u001b[43m,\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[38;5;241;43m0.3\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdetector\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlabel_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mimages_path\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mimage_path\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn[8], line 17\u001b[0m, in \u001b[0;36mevaluate_detector\u001b[1;34m(min_pixel, max_occlusion, max_truncation, detector, path, images_path)\u001b[0m\n\u001b[0;32m     12\u001b[0m cnt \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[0;32m     14\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m one_path \u001b[38;5;129;01min\u001b[39;00m tqdm\u001b[38;5;241m.\u001b[39mtqdm(os\u001b[38;5;241m.\u001b[39mlistdir(path), desc\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mProcessing\u001b[39m\u001b[38;5;124m\"\u001b[39m, unit\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfile\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[0;32m     15\u001b[0m \u001b[38;5;66;03m# for one_path in ['000003.txt']:\u001b[39;00m\n\u001b[0;32m     16\u001b[0m     \u001b[38;5;66;03m# print(one_path)\u001b[39;00m\n\u001b[1;32m---> 17\u001b[0m     img \u001b[38;5;241m=\u001b[39m \u001b[43mcv2\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mimread\u001b[49m\u001b[43m(\u001b[49m\u001b[43mos\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpath\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mjoin\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimages_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mone_path\u001b[49m\u001b[43m[\u001b[49m\u001b[43m:\u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[38;5;241;43m3\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mpng\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     18\u001b[0m     \u001b[38;5;66;03m# print(img)\u001b[39;00m\n\u001b[0;32m     19\u001b[0m     detector\u001b[38;5;241m.\u001b[39mDetectFrame(img)\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "#Medium task\n",
    "precision, recall, f1 = evaluate_detector(25,1,0.3, detector, label_path, images_path = image_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "object_types = [\"Car\", \"Pedestrian\", \"Truck\", \"Cyclist\", \"Other\"]\n",
    "\n",
    "# Tạo DataFrame từ các giá trị\n",
    "df = pd.DataFrame({\n",
    "    \"Object Type\": object_types,\n",
    "    \"Precision\": precision,\n",
    "    \"Recall\": recall,\n",
    "    \"F1\": f1\n",
    "})\n",
    "\n",
    "# Hiển thị DataFrame dưới dạng bảng\n",
    "print(df.to_string(index=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hard task"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing:   3%|▎         | 227/7481 [01:57<1:02:47,  1.93file/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[12], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m#hard task\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m precision, recall, f1 \u001b[38;5;241m=\u001b[39m \u001b[43mevaluate_detector\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m25\u001b[39;49m\u001b[43m,\u001b[49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m,\u001b[49m\u001b[38;5;241;43m0.5\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdetector\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlabel_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mimages_path\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mimage_path\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn[8], line 19\u001b[0m, in \u001b[0;36mevaluate_detector\u001b[1;34m(min_pixel, max_occlusion, max_truncation, detector, path, images_path)\u001b[0m\n\u001b[0;32m     17\u001b[0m img \u001b[38;5;241m=\u001b[39m cv2\u001b[38;5;241m.\u001b[39mimread(os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(images_path, one_path[:\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m3\u001b[39m] \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mpng\u001b[39m\u001b[38;5;124m'\u001b[39m))\n\u001b[0;32m     18\u001b[0m \u001b[38;5;66;03m# print(img)\u001b[39;00m\n\u001b[1;32m---> 19\u001b[0m \u001b[43mdetector\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mDetectFrame\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimg\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     20\u001b[0m cars \u001b[38;5;241m=\u001b[39m []\n\u001b[0;32m     21\u001b[0m pedestrian \u001b[38;5;241m=\u001b[39m []\n",
      "File \u001b[1;32md:\\VinBigData_Training_2024\\Computer_Vision\\FinalProject\\ADAS-LDWS-LKAS-FCWS\\deep_learning\\ObjectDetector\\yoloDetector.py:162\u001b[0m, in \u001b[0;36mYoloDetector.DetectFrame\u001b[1;34m(self, srcimg)\u001b[0m\n\u001b[0;32m    159\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mDetectFrame\u001b[39m(\u001b[38;5;28mself\u001b[39m, srcimg : cv2) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    160\u001b[0m \tinput_tensor, scaler \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m__prepare_input(srcimg)\n\u001b[1;32m--> 162\u001b[0m \toutput_from_network \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mengine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mengine_inference\u001b[49m\u001b[43m(\u001b[49m\u001b[43minput_tensor\u001b[49m\u001b[43m)\u001b[49m[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39msqueeze(axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m)\n\u001b[0;32m    164\u001b[0m \t_raw_boxes, _raw_class_ids, _raw_class_confs, _raw_kpss \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m__process_output(output_from_network)\n\u001b[0;32m    166\u001b[0m \ttransform_boxes \u001b[38;5;241m=\u001b[39m scaler\u001b[38;5;241m.\u001b[39mconvert_boxes_coordinate(_raw_boxes)\n",
      "File \u001b[1;32md:\\VinBigData_Training_2024\\Computer_Vision\\FinalProject\\ADAS-LDWS-LKAS-FCWS\\deep_learning\\ObjectDetector\\..\\coreEngine.py:185\u001b[0m, in \u001b[0;36mOnnxEngine.engine_inference\u001b[1;34m(self, input_tensor)\u001b[0m\n\u001b[0;32m    184\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mengine_inference\u001b[39m(\u001b[38;5;28mself\u001b[39m, input_tensor):\n\u001b[1;32m--> 185\u001b[0m \toutput \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msession\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m__output_names\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m{\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m__input_names\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43minput_tensor\u001b[49m\u001b[43m}\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    186\u001b[0m \t\u001b[38;5;28;01mreturn\u001b[39;00m output\n",
      "File \u001b[1;32mc:\\Users\\Admin\\.conda\\envs\\main_py312\\Lib\\site-packages\\onnxruntime\\capi\\onnxruntime_inference_collection.py:220\u001b[0m, in \u001b[0;36mSession.run\u001b[1;34m(self, output_names, input_feed, run_options)\u001b[0m\n\u001b[0;32m    218\u001b[0m     output_names \u001b[38;5;241m=\u001b[39m [output\u001b[38;5;241m.\u001b[39mname \u001b[38;5;28;01mfor\u001b[39;00m output \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_outputs_meta]\n\u001b[0;32m    219\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 220\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_sess\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[43moutput_names\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minput_feed\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrun_options\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    221\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m C\u001b[38;5;241m.\u001b[39mEPFail \u001b[38;5;28;01mas\u001b[39;00m err:\n\u001b[0;32m    222\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_enable_fallback:\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "#hard task\n",
    "precision, recall, f1 = evaluate_detector(25,2,0.5, detector, label_path, images_path = image_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "object_types = [\"Car\", \"Pedestrian\", \"Truck\", \"Cyclist\", \"Other\"]\n",
    "\n",
    "# Tạo DataFrame từ các giá trị\n",
    "df = pd.DataFrame({\n",
    "    \"Object Type\": object_types,\n",
    "    \"Precision\": precision,\n",
    "    \"Recall\": recall,\n",
    "    \"F1\": f1\n",
    "})\n",
    "\n",
    "# Hiển thị DataFrame dưới dạng bảng\n",
    "print(df.to_string(index=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "object_types = [\"Car\", \"Pedestrian\", \"Truck\", \"Cyclist\", \"Other\"]\n",
    "\n",
    "# Tạo DataFrame từ các giá trị\n",
    "df = pd.DataFrame({\n",
    "    \"Object Type\": object_types,\n",
    "    \"Precision\": precision,\n",
    "    \"Recall\": recall,\n",
    "    \"F1\": f1\n",
    "})\n",
    "\n",
    "# Hiển thị DataFrame dưới dạng bảng\n",
    "print(df.to_string(index=False))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
